{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f15b570",
   "metadata": {},
   "source": [
    "Эта записная книжка проведет вас через шаги, необходимые для обучения базовой модели деревьев с градиентным усилением с использованием леса принятия решений TensorFlow на наборе данных «Успеваемость учащихся из игры», доступном для этого соревнования, чтобы предсказать, будут ли игроки правильно отвечать на вопросы. Мы будем загружать данные из файла CSV. Грубо код будет выглядеть так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7c3c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"project/dataset.csv\")\n",
    "tf_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(dataset, label=\"my_label\")\n",
    "\n",
    "model = tfdf.keras.GradientBoostedTreesModel()\n",
    "model.fit(tf_dataset)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b5a927",
   "metadata": {},
   "source": [
    "Мы также научимся оптимизировать чтение больших наборов данных, проработаем некоторые функции, визуализируем данные и рассчитываем лучшие результаты с помощью F1-показателя.\n",
    "\n",
    "Леса принятия решений — это семейство древовидных моделей, включая случайные леса и деревья с градиентным усилением. Это лучшее место для начала работы с табличными данными, и они часто превосходят (или обеспечивают надежный базовый уровень) до того, как вы начнете экспериментировать с нейронными сетями.\n",
    "\n",
    "Один из ключевых аспектов TensorFlow Decision Forests, который делает его еще более подходящим для этого соревнования, особенно с учетом ограничений времени выполнения, заключается в том, что он был тщательно протестирован для обучения и вывода на процессорах, что позволяет обучать его на младших машинах. ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c0a8fb",
   "metadata": {},
   "source": [
    "# Import the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63971cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134265fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow Decision Forests v\" + tfdf.__version__)\n",
    "print(\"TensorFlow Addons v\" + tfa.__version__)\n",
    "print(\"TensorFlow v\" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8987a30",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e488d7f",
   "metadata": {},
   "source": [
    "Поскольку набор данных огромен, некоторые люди могут столкнуться с ошибками памяти при чтении набора данных из csv. Чтобы избежать этого, мы попытаемся оптимизировать память, используемую Pandas для загрузки и хранения набора данных.\n",
    "\n",
    "Когда Pandas загружает набор данных, по умолчанию он автоматически определяет типы данных различных столбцов. Независимо от максимального значения, хранящегося в этих столбцах, Pandas присваивает int64 для числовых столбцов, float64 для столбцов с плавающей запятой, объект dtype для строковых столбцов и т. д.\n",
    "\n",
    "Мы можем уменьшить размер этих столбцов в памяти, понизив числовые столбцы до меньших типов (например, int8, int32, float32 и т. д.), если их максимальные значения не нуждаются в больших типах для хранения (например, int64, float64). и т. д.).\n",
    "\n",
    "Точно так же Pandas автоматически определяет строковые столбцы как тип данных объекта. Чтобы уменьшить использование памяти строковыми столбцами, в которых хранятся категориальные данные, мы указываем их тип данных как категорию.\n",
    "\n",
    "Многие столбцы в этом наборе данных могут быть преобразованы в меньшие типы.\n",
    "\n",
    "Мы предоставим пандам набор dtypes для столбцов при чтении набора данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebdbd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.kaggle.com/competitions/predict-student-performance-from-game-play/discussion/384359\n",
    "dtypes={\n",
    "    'elapsed_time':np.int32,\n",
    "    'event_name':'category',\n",
    "    'name':'category',\n",
    "    'level':np.uint8,\n",
    "    'room_coor_x':np.float32,\n",
    "    'room_coor_y':np.float32,\n",
    "    'screen_coor_x':np.float32,\n",
    "    'screen_coor_y':np.float32,\n",
    "    'hover_duration':np.float32,\n",
    "    'text':'category',\n",
    "    'fqid':'category',\n",
    "    'room_fqid':'category',\n",
    "    'text_fqid':'category',\n",
    "    'fullscreen':'category',\n",
    "    'hq':'category',\n",
    "    'music':'category',\n",
    "    'level_group':'category'}\n",
    "\n",
    "dataset_df = pd.read_csv('/kaggle/input/predict-student-performance-from-game-play/train.csv', dtype=dtypes)\n",
    "print(\"Full train dataset shape is {}\".format(dataset_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b620d8",
   "metadata": {},
   "source": [
    "Данные состоят из 20 столбцов и 26296946 записей. Мы можем увидеть все 20 измерений нашего набора данных, распечатав первые 5 записей, используя следующий код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dcd738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 examples\n",
    "dataset_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bd5246",
   "metadata": {},
   "source": [
    "Обратите внимание, что session_id однозначно идентифицирует сеанс пользователя."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d16d3b4",
   "metadata": {},
   "source": [
    "Load the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676cb5a4",
   "metadata": {},
   "source": [
    "Метки для обучающего набора данных хранятся в файле train_labels.csv. Он состоит из информации о том, правильно ли ответил пользователь в конкретном сеансе на каждый вопрос. Загрузите данные меток, выполнив следующий код."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a844e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('/kaggle/input/predict-student-performance-from-game-play/train_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def388d8",
   "metadata": {},
   "source": [
    "Каждое значение в столбце session_id представляет собой комбинацию сеанса и номера вопроса. Мы разделим их на отдельные столбцы для удобства использования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6bee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
    "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da85b04",
   "metadata": {},
   "source": [
    "Давайте посмотрим на первые 5 записей меток, используя следующий код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44d1db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 examples\n",
    "labels.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4170b8",
   "metadata": {},
   "source": [
    "Наша цель — обучить модели для каждого вопроса, чтобы правильно предсказать метку для любого входного пользовательского сеанса."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd07b8d",
   "metadata": {},
   "source": [
    "# Bar chart for label column: correct\n",
    "# Гистограмма для столбца меток: верно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d886097b",
   "metadata": {},
   "source": [
    "Сначала мы построим гистограмму для значений метки правильно.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e83ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "plot_df = labels.correct.value_counts()\n",
    "plot_df.plot(kind=\"bar\", color=['b', 'c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b0c5d0",
   "metadata": {},
   "source": [
    "Теперь давайте нанесем на график значения столбца метки, правильные для каждого вопроса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5529f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 20))\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "plt.suptitle(\"\\\"Correct\\\" column values for each question\", fontsize=14, y=0.94)\n",
    "for n in range(1,19):\n",
    "    #print(n, str(n))\n",
    "    ax = plt.subplot(6, 3, n)\n",
    "\n",
    "    # filter df and plot ticker on the new subplot axis\n",
    "    plot_df = labels.loc[labels.q == n]\n",
    "    plot_df = plot_df.correct.value_counts()\n",
    "    plot_df.plot(ax=ax, kind=\"bar\", color=['b', 'c'])\n",
    "    \n",
    "    # chart formatting\n",
    "    ax.set_title(\"Question \" + str(n))\n",
    "    ax.set_xlabel(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ba16c",
   "metadata": {},
   "source": [
    "Подготовьте набор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6351c19",
   "metadata": {},
   "source": [
    "Как указано в обзоре конкурса, набор данных представляет нам вопросы и данные в порядке уровней — сегментов уровней (представленных столбцом level_group) 0–4, 5–12 и 13–22. Мы должны предсказать правильность вопросов каждого сегмента по мере их представления. Для этого мы создадим основные агрегатные функции из соответствующих столбцов. Вы можете создать больше функций, чтобы повысить свои баллы.\n",
    "\n",
    "Во-первых, мы создадим два отдельных списка с именами категориальных столбцов и числовых столбцов. Мы будем избегать столбцов fullscreen, hq и music, поскольку они не добавляют никакой полезной ценности для этой постановки задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea4148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL = ['event_name', 'name','fqid', 'room_fqid', 'text_fqid']\n",
    "NUMERICAL = ['elapsed_time','level','page','room_coor_x', 'room_coor_y', \n",
    "        'screen_coor_x', 'screen_coor_y', 'hover_duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e2fef",
   "metadata": {},
   "source": [
    "Для каждого категориального столбца мы сначала сгруппируем набор данных по session_id и level_group. Затем мы подсчитаем количество различных элементов в столбце для каждой группы и временно сохраним его.\n",
    "\n",
    "Для всех числовых столбцов мы сгруппируем набор данных по идентификатору сеанса и level_group. Вместо подсчета количества отдельных элементов мы вычислим среднее значение и стандартное отклонение числового столбца для каждой группы и временно сохраним его.\n",
    "\n",
    "После этого мы объединим временные фреймы данных, которые мы создали на предыдущем шаге, для каждого столбца, чтобы создать наш новый набор данных с инженерными функциями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff94a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.kaggle.com/code/cdeotte/random-forest-baseline-0-664/notebook\n",
    "\n",
    "def feature_engineer(dataset_df):\n",
    "    dfs = []\n",
    "    for c in CATEGORICAL:\n",
    "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('nunique')\n",
    "        tmp.name = tmp.name + '_nunique'\n",
    "        dfs.append(tmp)\n",
    "    for c in NUMERICAL:\n",
    "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('mean')\n",
    "        dfs.append(tmp)\n",
    "    for c in NUMERICAL:\n",
    "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('std')\n",
    "        tmp.name = tmp.name + '_std'\n",
    "        dfs.append(tmp)\n",
    "    dataset_df = pd.concat(dfs,axis=1)\n",
    "    dataset_df = dataset_df.fillna(-1)\n",
    "    dataset_df = dataset_df.reset_index()\n",
    "    dataset_df = dataset_df.set_index('session_id')\n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514ef4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = feature_engineer(dataset_df)\n",
    "print(\"Full prepared dataset shape is {}\".format(dataset_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5265e1",
   "metadata": {},
   "source": [
    "Наш специально спроектированный набор данных состоит из 22 столбцов и 70686 записей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0d9563",
   "metadata": {},
   "source": [
    "# Basic exploration of the prepared dataset\n",
    "# Базовое исследование подготовленного набора данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b3f587",
   "metadata": {},
   "source": [
    "Давайте распечатаем первые 5 записей, используя следующий код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2546fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 examples\n",
    "dataset_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ad112",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73b84ab",
   "metadata": {},
   "source": [
    "# Numerical data distribution\n",
    "# Распределение числовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31543f7e",
   "metadata": {},
   "source": [
    "Давайте нанесем несколько числовых столбцов и их значение для каждой группы level_group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adebfae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(3, 2, figsize=(10, 10))\n",
    "\n",
    "for name, data in dataset_df.groupby('level_group'):\n",
    "    axis[0, 0].plot(range(1, len(data['room_coor_x_std'])+1), data['room_coor_x_std'], label=name)\n",
    "    axis[0, 1].plot(range(1, len(data['room_coor_y_std'])+1), data['room_coor_y_std'], label=name)\n",
    "    axis[1, 0].plot(range(1, len(data['screen_coor_x_std'])+1), data['screen_coor_x_std'], label=name)\n",
    "    axis[1, 1].plot(range(1, len(data['screen_coor_y_std'])+1), data['screen_coor_y_std'], label=name)\n",
    "    axis[2, 0].plot(range(1, len(data['hover_duration'])+1), data['hover_duration_std'], label=name)\n",
    "    axis[2, 1].plot(range(1, len(data['elapsed_time_std'])+1), data['elapsed_time_std'], label=name)\n",
    "    \n",
    "\n",
    "axis[0, 0].set_title('room_coor_x')\n",
    "axis[0, 1].set_title('room_coor_y')\n",
    "axis[1, 0].set_title('screen_coor_x')\n",
    "axis[1, 1].set_title('screen_coor_y')\n",
    "axis[2, 0].set_title('hover_duration')\n",
    "axis[2, 1].set_title('elapsed_time_std')\n",
    "\n",
    "for i in range(3):\n",
    "    axis[i, 0].legend()\n",
    "    axis[i, 1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8189c44d",
   "metadata": {},
   "source": [
    "Теперь давайте разделим набор данных на наборы данных для обучения и тестирования:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bd51ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, test_ratio=0.20):\n",
    "    USER_LIST = dataset.index.unique()\n",
    "    split = int(len(USER_LIST) * (1 - 0.20))\n",
    "    return dataset.loc[USER_LIST[:split]], dataset.loc[USER_LIST[split:]]\n",
    "\n",
    "train_x, valid_x = split_dataset(dataset_df)\n",
    "print(\"{} examples in training, {} examples in testing.\".format(\n",
    "    len(train_x), len(valid_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62dd0da",
   "metadata": {},
   "source": [
    "# Select a Model\n",
    "# Выберите модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3802fe",
   "metadata": {},
   "source": [
    "Есть несколько моделей на основе дерева на ваш выбор.\n",
    "\n",
    "- RandomForestModel\n",
    "- GradientBoostedTreesModel\n",
    "- CartModel\n",
    "- DistributedGradientBoostedTreesModel\n",
    "Мы можем перечислить все доступные модели в TensorFlow Decision Forests, используя следующий код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d98344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdf.keras.get_all_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114ce923",
   "metadata": {},
   "source": [
    "Для начала мы будем работать с моделью деревьев с усилением градиента. Это один из известных алгоритмов обучения Decision Forest.\n",
    "\n",
    "Дерево решений с градиентным усилением представляет собой набор неглубоких деревьев решений, обучаемых последовательно. Каждое дерево обучается предсказывать, а затем «исправлять» ошибки ранее обученных деревьев."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe307300",
   "metadata": {},
   "source": [
    "# How can I configure a tree-based model?\n",
    "# Как настроить древовидную модель?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3168fa6",
   "metadata": {},
   "source": [
    "TensorFlow Decision Forests предоставляет вам хорошие значения по умолчанию (например, самые высокие гиперпараметры в наших тестах, слегка измененные для запуска в разумные сроки). Если вы хотите настроить алгоритм обучения, вы найдете множество опций, которые вы можете изучить, чтобы получить максимально возможную точность.\n",
    "\n",
    "Вы можете выбрать шаблон и/или установить параметры следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c013d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = tfdf.keras.GradientBoostedTreesModel(hyperparameter_template=\"benchmark_rank1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6956cddb",
   "metadata": {},
   "source": [
    "You can read more here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0100816",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2673f950",
   "metadata": {},
   "source": [
    "Мы будем обучать модель для каждого вопроса, чтобы предсказать, будет ли пользователь правильно отвечать на вопрос. Всего в наборе данных 18 вопросов. Следовательно, мы будем обучать 18 моделей, по одной на каждый вопрос.\n",
    "\n",
    "Нам нужно предоставить несколько структур данных для нашего цикла обучения, чтобы хранить обученные модели, прогнозы для набора проверки и оценки для обученных моделей.\n",
    "\n",
    "Мы создадим их, используя следующий код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f2aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получить уникальный список пользовательских сеансов в наборе данных проверки. Мы назначили\n",
    "# `session_id` в качестве индекса нашего набора данных с инженерными функциями. Отсюда получение\n",
    "# уникальные значения в столбце index дадут нам список пользователей в\n",
    "# набор для проверки.\n",
    "VALID_USER_LIST = valid_x.index.unique()\n",
    "\n",
    "# Создать фрейм данных для хранения прогнозов каждого вопроса для всех пользователей\n",
    "# в проверочном наборе.\n",
    "# Для этого требуется размер фрейма данных:\n",
    "# (количество: пользователей в наборе проверки x количество вопросов).\n",
    "# Мы инициализируем все предсказанные значения во фрейме данных нулем.\n",
    "# Столбец индекса фрейма данных - это пользовательский `session_id`.\n",
    "prediction_df = pd.DataFrame(data=np.zeros((len(VALID_USER_LIST),18)), index=VALID_USER_LIST)\n",
    "\n",
    "# Создайте пустой словарь для хранения моделей, созданных для каждого вопроса.\n",
    "models = {}\n",
    "\n",
    "# Создайте пустой словарь для хранения оценки каждого вопроса.\n",
    "evaluation_dict ={}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f19f5c",
   "metadata": {},
   "source": [
    "Перед обучением данных мы должны понять, как level_groups и вопросы связаны друг с другом.\n",
    "\n",
    "В этой игре первая контрольная точка викторины (т.е. вопросы с 1 по 3) наступает после прохождения уровней с 0 по 4. Таким образом, для обучающих вопросов с 1 по 3 мы будем использовать данные из level_group 0-4. Точно так же мы будем использовать данные из level_group 5-12 для обучения вопросам с 4 по 13 и данные из level_group 13-22 для обучения вопросам с 14 по 18.\n",
    "\n",
    "Мы будем обучать модель для каждого вопроса и хранить обученную модель в словаре моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df10fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Повторить вопросы с 1 по 18, чтобы обучить модели для каждого вопроса, оценить\n",
    "# обученную модель и сохранить предсказанные значения.\n",
    "for q_no in range(1,19):\n",
    "\n",
    "    # Выберите группу уровня для вопроса на основе q_no.\n",
    "    if q_no<=3: grp = '0-4'\n",
    "    elif q_no<=13: grp = '5-12'\n",
    "    elif q_no<=22: grp = '13-22'\n",
    "    print(\"### q_no\", q_no, \"grp\", grp)\n",
    "    \n",
    "        \n",
    "    # Отфильтровать строки в наборах данных на основе выбранной группы уровней.\n",
    "    train_df = train_x.loc[train_x.level_group == grp]\n",
    "    train_users = train_df.index.values\n",
    "    valid_df = valid_x.loc[valid_x.level_group == grp]\n",
    "    valid_users = valid_df.index.values\n",
    "\n",
    "    # Выберите метки для соответствующего q_no.\n",
    "    train_labels = labels.loc[labels.q==q_no].set_index('session').loc[train_users]\n",
    "    valid_labels = labels.loc[labels.q==q_no].set_index('session').loc[valid_users]\n",
    "\n",
    "    # Добавляем метку к отфильтрованным наборам данных.\n",
    "    train_df[\"correct\"] = train_labels[\"correct\"]\n",
    "    valid_df[\"correct\"] = valid_labels[\"correct\"]\n",
    "\n",
    "    # Прежде чем мы сможем обучить модель, необходимо выполнить еще один шаг.\n",
    "     # Нам нужно преобразовать набор данных из формата Pandas (pd.DataFrame)\n",
    "     # в формат наборов данных TensorFlow (tf.data.Dataset).\n",
    "     # TensorFlow Datasets — это высокопроизводительная библиотека для загрузки данных.\n",
    "     # что полезно при обучении нейронных сетей с помощью ускорителей, таких как GPU и TPU.\n",
    "     # Мы опускаем `level_group`, так как он больше не нужен для обучения.\n",
    "    train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df.loc[:, train_df.columns != 'level_group'], label=\"correct\")\n",
    "    valid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(valid_df.loc[:, valid_df.columns != 'level_group'], label=\"correct\")\n",
    "\n",
    "    # Теперь мы создадим модель деревьев с усилением градиента с настройками по умолчанию.\n",
    "     # По умолчанию модель настроена на обучение задаче классификации.\n",
    "    gbtm = tfdf.keras.GradientBoostedTreesModel(verbose=0)\n",
    "    gbtm.compile(metrics=[\"accuracy\"])\n",
    "\n",
    "    # Обучить модель.\n",
    "    gbtm.fit(x=train_ds)\n",
    "\n",
    "    # Сохраняем модель\n",
    "    models[f'{grp}_{q_no}'] = gbtm\n",
    "\n",
    "    # Оцените обученную модель в наборе данных проверки и сохраните\n",
    "     # точность оценки в `evaluation_dict`.\n",
    "    inspector = gbtm.make_inspector()\n",
    "    inspector.evaluation()\n",
    "    evaluation = gbtm.evaluate(x=valid_ds,return_dict=True)\n",
    "    evaluation_dict[q_no] = evaluation[\"accuracy\"]         \n",
    "\n",
    "    # Используйте обученную модель, чтобы делать прогнозы по набору данных проверки и\n",
    "     # сохранить предсказанные значения в кадре данных `prediction_df`.\n",
    "    predict = gbtm.predict(x=valid_ds)\n",
    "    prediction_df.loc[valid_users, q_no-1] = predict.flatten()     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205bf66c",
   "metadata": {},
   "source": [
    "# Inspect the Accuracy of the models.¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cc7341",
   "metadata": {},
   "source": [
    "Мы обучили модель для каждого вопроса. Теперь давайте проверим точность каждой модели и общую точность всех моделей вместе взятых.\n",
    "\n",
    "Примечание. Поскольку распределение меток несбалансировано, мы не можем делать предположения о производительности модели только на основе показателя точности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0eccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in evaluation_dict.items():\n",
    "  print(f\"question {name}: accuracy {value:.4f}\")\n",
    "\n",
    "print(\"\\nAverage accuracy\", sum(evaluation_dict.values())/18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ebd92b",
   "metadata": {},
   "source": [
    "# Visualize the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09219fe7",
   "metadata": {},
   "source": [
    "Одним из преимуществ древовидных моделей является то, что мы можем легко их визуализировать. По умолчанию количество деревьев, используемых в случайных лесах, равно 300.\n",
    "\n",
    "Давайте выберем одну модель из списка моделей и выберем дерево для отображения ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ffd66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdf.model_plotter.plot_model_in_colab(models['0-4_1'], tree_idx=0, max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf02943",
   "metadata": {},
   "source": [
    "# Variable importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1183eb09",
   "metadata": {},
   "source": [
    "Переменная важность обычно указывает, насколько функция влияет на прогнозы или качество модели. Существует несколько способов определения важных функций с помощью TensorFlow Decision Forest. Давайте выберем одну модель из списка моделей и проверим ее.\n",
    "\n",
    "Давайте перечислим доступные значения переменных для деревьев решений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd03d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspector = models['0-4_1'].make_inspector()\n",
    "\n",
    "print(f\"Available variable importances:\")\n",
    "for importance in inspector.variable_importances().keys():\n",
    "  print(\"\\t\", importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90916b28",
   "metadata": {},
   "source": [
    "В качестве примера давайте отобразим важные функции для важности переменной NUM_AS_ROOT.\n",
    "\n",
    "Чем больше показатель важности для NUM_AS_ROOT, тем большее влияние он оказывает на результат модели для вопроса 1 (т. е. модель[\"0-4_1\"]).\n",
    "\n",
    "По умолчанию список отсортирован от наиболее важного к наименее важному. Из вывода вы можете сделать вывод, что функция в верхней части списка используется в качестве корневого узла в большинстве деревьев в деревьях с градиентным усилением, чем любая другая функция."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abd2ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each line is: (feature name, (index of the feature), importance score)\n",
    "inspector.variable_importances()[\"NUM_AS_ROOT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d5702b",
   "metadata": {},
   "source": [
    "# Threshold-Moving for Imbalanced Classification\n",
    "# Изменение порога для несбалансированной классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb6cbd",
   "metadata": {},
   "source": [
    "Поскольку значения правильного столбца довольно несбалансированы, использование порога по умолчанию 0,5 для сопоставления прогнозов с классами 0 или 1 может привести к снижению производительности. В таких случаях, чтобы улучшить производительность, мы вычисляем балл F1 для определенного диапазона пороговых значений и пытаемся найти лучший порог, также известный как порог с наивысшим баллом F1. Затем мы будем использовать этот порог для сопоставления предсказанных вероятностей с метками классов 0 или 1.\n",
    "\n",
    "Обратите внимание, что мы используем показатель F1, так как это лучший показатель, чем точность, для оценки проблем с дисбалансом классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131907ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим фрейм данных нужного размера:\n",
    "# (количество: пользователей в проверочном наборе x количество: вопросов) инициализированы нулевыми значениями\n",
    "# для хранения истинных значений метки `correct`.\n",
    "true_df = pd.DataFrame(data=np.zeros((len(VALID_USER_LIST),18)), index=VALID_USER_LIST)\n",
    "for i in range(18):\n",
    "    # Получить истинные метки.\n",
    "    tmp = labels.loc[labels.q == i+1].set_index('session').loc[VALID_USER_LIST]\n",
    "    true_df[i] = tmp.correct.values\n",
    "\n",
    "max_score = 0; best_threshold = 0\n",
    "\n",
    "# Прокрутите пороговые значения от 0,4 до 0,8 и выберите порог с помощью\n",
    "# самый высокий балл F1.\n",
    "for threshold in np.arange(0.4,0.8,0.01):\n",
    "    metric = tfa.metrics.F1Score(num_classes=2,average=\"macro\",threshold=threshold)\n",
    "    y_true = tf.one_hot(true_df.values.reshape((-1)), depth=2)\n",
    "    y_pred = tf.one_hot((prediction_df.values.reshape((-1))>threshold).astype('int'), depth=2)\n",
    "    metric.update_state(y_true, y_pred)\n",
    "    f1_score = metric.result().numpy()\n",
    "    if f1_score > max_score:\n",
    "        max_score = f1_score\n",
    "        best_threshold = threshold\n",
    "        \n",
    "print(\"Best threshold \", best_threshold, \"\\tF1 score \", max_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b1912f",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eeb5df",
   "metadata": {},
   "source": [
    "Представление Здесь вы будете использовать расчет best_threshold в предыдущей ячейке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59269420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference\n",
    "# https://www.kaggle.com/code/philculliton/basic-submission-demo\n",
    "# https://www.kaggle.com/code/cdeotte/random-forest-baseline-0-664/notebook\n",
    "\n",
    "\n",
    "import jo_wilder\n",
    "env = jo_wilder.make_env()\n",
    "iter_test = env.iter_test()\n",
    "\n",
    "limits = {'0-4':(1,4), '5-12':(4,14), '13-22':(14,19)}\n",
    "\n",
    "for (test, sample_submission) in iter_test:\n",
    "    test_df = feature_engineer(test)\n",
    "    grp = test_df.level_group.values[0]\n",
    "    a,b = limits[grp]\n",
    "    for t in range(a,b):\n",
    "        gbtm = models[f'{grp}_{t}']\n",
    "        test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_df.loc[:, test_df.columns != 'level_group'])\n",
    "        predictions = gbtm.predict(test_ds)\n",
    "        mask = sample_submission.session_id.str.contains(f'q{t}')\n",
    "        n_predictions = (predictions > best_threshold).astype(int)\n",
    "        sample_submission.loc[mask,'correct'] = n_predictions.flatten()\n",
    "    \n",
    "    env.predict(sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370269a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! head submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
